{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hollywood-graduation",
   "metadata": {},
   "source": [
    "### **D2APR: Aprendizado de M√°quina e Reconhecimento de Padr√µes** (IFSP, Campinas) <br/>\n",
    "**Prof**: Samuel Martins (Samuka) <br/>\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>. <br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-calgary",
   "metadata": {},
   "source": [
    "### Custom CSS style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-composer",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".dashed-box {\n",
    "    border: 1px dashed black !important;\n",
    "}\n",
    ".dashed-box tr {\n",
    "  background-color: white !important;  \n",
    "}\n",
    ".alt-tab {\n",
    "    background-color: black;\n",
    "    color: #ffc351;\n",
    "    padding: 4px;\n",
    "    font-size: 1em;\n",
    "    font-weight: bold;\n",
    "    font-family: monospace;\n",
    "}\n",
    "// add your CSS styling here\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-roads",
   "metadata": {},
   "source": [
    "<span style='font-size: 2.5em'><b>California Housing üè°</b></span><br/>\n",
    "<span style='font-size: 1.5em'>Predict the median housing price in California districts</span>\n",
    "\n",
    "<span style=\"background-color: #ffc351; padding: 4px; font-size: 1em;\"><b>Sprint 5</b></span>\n",
    "\n",
    "<img src=\"./imgs/california-flag.png\" width=300/>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-county",
   "metadata": {},
   "source": [
    "## Before starting this notebook\n",
    "This jupyter notebook is designed for **experimental and teaching purposes**. <br/>\n",
    "Although it is (relatively) well organized, it aims at solving the _target problem_ by evaluating (and documenting) _different solutions_ for somes steps of the **machine learning pipeline** ‚Äî see the ***Machine Learning Project Checklist by xavecoding***. <br/>\n",
    "We tried to make this notebook as literally a _notebook_. Thus, it contains notes, drafts, comments, etc.<br/>\n",
    "\n",
    "For teaching purposes, some parts of the notebook may be _overcommented_. Moreover, to simulate a real development scenario, we will divide our solution and experiments into **\"sprints\"** in which each sprint has some goals (e.g., perform _feature selection_, train more ML models, ...). <br/>\n",
    "The **sprint goal** will be stated at the beginning of the notebook.\n",
    "\n",
    "A ***final notebook*** (or any other kind of presentation) that compiles and summarizes all sprints ‚Äî the target problem, solutions, and findings ‚Äî should be created later.\n",
    "\n",
    "#### Conventions\n",
    "\n",
    "<ul>\n",
    "    <li>üí° indicates a tip. </li>\n",
    "    <li> ‚ö†Ô∏è indicates a warning message. </li>\n",
    "    <li><span class='alt-tab'>alt tab</span> indicates and an extra content (<i>e.g.</i>, slides) to explain a given concept.</li>\n",
    "</ul>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-truck",
   "metadata": {},
   "source": [
    "## üéØ Sprint Goals\n",
    "- Evaluate Polynomial Regression Models\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-jones",
   "metadata": {},
   "source": [
    "### 0. Imports and default settings for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 5),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-ensemble",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è 5. Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-clerk",
   "metadata": {},
   "source": [
    "To use **Polynomial Regression**, we need to decide _which features_ will be used/considered first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-corpus",
   "metadata": {},
   "source": [
    "### 5.1. Load the cleaned training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-editing",
   "metadata": {},
   "source": [
    "Let's consider the training and testing sets already cleaned (sprint #2):\n",
    "- Drop duplicated instances (no found)\n",
    "- Drop instances with `housing_median_age` capped at 52\n",
    "- Drop instances with `median_house_value` capped at 500001.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-question",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the cleaned training set\n",
    "housing_train = pd.read_csv('./datasets/housing_train_sprint-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-klein",
   "metadata": {},
   "source": [
    "### 5.2. Quick EDA to get insights about the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-contractor",
   "metadata": {},
   "source": [
    "#### **Generate aggregate features**\n",
    "Let's also analyse the new features created in the previous sprints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-mouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train_eda = housing_train.copy()\n",
    "\n",
    "housing_train_eda[\"rooms_per_household\"] = housing_train_eda[\"total_rooms\"] / housing_train_eda[\"households\"]\n",
    "housing_train_eda[\"bedrooms_per_room\"] = housing_train_eda[\"total_bedrooms\"] / housing_train_eda[\"total_rooms\"]\n",
    "housing_train_eda[\"population_per_household\"] = housing_train_eda[\"population\"] / housing_train_eda[\"households\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train_eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train_eda.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(housing_train_eda, x_vars=['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income'],  y_vars=['median_house_value'], height=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(housing_train_eda, x_vars=['rooms_per_household', 'bedrooms_per_room', 'population_per_household'],  y_vars=['median_house_value'], height=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-sugar",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "By looking at the scatter plots, we cannot identify a specific relationship (linear, quadratic, cubic, ...) between the _features_ and the _outcome_ (`median_house_value`). <br/>\n",
    "As observersed in previous sprints, the `median_income` seems to have a _'linear'_ relationship with the `median_house_value`.\n",
    "\n",
    "The `population_per_household` has significative _outliers_ which impair its visualization. Let's **remove** these outliers to try to improve the visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-composition",
   "metadata": {},
   "source": [
    "##### **Removing outliers for `population_per_household`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-fighter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR outlier detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-closer",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(housing_train_eda_without_outliers, x_vars=['rooms_per_household', 'bedrooms_per_room', 'population_per_household'],  y_vars=['median_house_value'], height=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-sixth",
   "metadata": {},
   "source": [
    "Now, we can see the true dispersion of the `population_per_household` and the `median_house_value`. However there is not a clear relationship between them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-lemon",
   "metadata": {},
   "source": [
    "Let's then consider two scenarios for **Polynomial Regression**\n",
    "1. Use _only_ the `median_income`.\n",
    "2. Use _all features_ except those that generated the aggregate features (`total_rooms`, `total_bedrooms`, `population`, `household`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-knowing",
   "metadata": {},
   "source": [
    "### 5.3. Separate the _features_ and the _target outcome_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the target outcome into a numpy array\n",
    "y_train = housing_train['median_house_value'].values\n",
    "\n",
    "# overwrite the dataframe with only the features  \n",
    "housing_train = housing_train.drop(columns=['median_house_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-rhythm",
   "metadata": {},
   "source": [
    "### 5.4. Preprocessing Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-peninsula",
   "metadata": {},
   "source": [
    "#### **Scenario 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-treatment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline for numerical\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-antique",
   "metadata": {},
   "source": [
    "#### **Scenario 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attributes = housing_train.columns.drop('ocean_proximity')\n",
    "num_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the integer index of each attribute/column for the filtered dataframe by the numeric attributes:\n",
    "for index, column_name in enumerate(housing_train[num_attributes]):\n",
    "    print(f'{index} = {column_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### feature engineering method from the Sprint #4\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# our 3 new features are based on some the features: totalrooms, \n",
    "# column index\n",
    "rooms_col_idx, bedrooms_col_idx, population_col_idx, households_col_idx = 3, 4, 5, 6\n",
    "\n",
    "class HousingFeatEngineering(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    \n",
    "    def transform(self, X):\n",
    "        n_rows = X.shape[0]\n",
    "        \n",
    "        # creating the new features\n",
    "        rooms_per_household = X[:, rooms_col_idx] / X[:, households_col_idx]\n",
    "        population_per_household = X[:, population_col_idx] / X[:, households_col_idx]\n",
    "        bedrooms_per_room = X[:, bedrooms_col_idx] / X[:, rooms_col_idx]\n",
    "                \n",
    "        # to concatenate the new array as columns in our feature matrix, we need to reshape them first\n",
    "        rooms_per_household = rooms_per_household.reshape((n_rows, 1))\n",
    "        population_per_household = population_per_household.reshape((n_rows, 1))\n",
    "        bedrooms_per_room = bedrooms_per_room.reshape((n_rows, 1))\n",
    "        \n",
    "        # concatenating the new features into the feature matrix\n",
    "        X_out = np.hstack((X, rooms_per_household, population_per_household, bedrooms_per_room))\n",
    "        \n",
    "        return X_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-medicaid",
   "metadata": {},
   "source": [
    "The columns of **output numpy array** will correspond to: <br/>\n",
    "0 = longitude <br/>\n",
    "1 = latitude <br/>\n",
    "2 = housing_median_age <br/>\n",
    "3 = total_rooms <br/>\n",
    "4 = total_bedrooms <br/>\n",
    "5 = population <br/>\n",
    "6 = households <br/>\n",
    "7 = median_income <br/>\n",
    "8 = rooms_per_household <br/>\n",
    "9 = population_per_household <br/>\n",
    "10 = bedrooms_per_room <br/>\n",
    "\n",
    "To satisfy the scenario 2, we need to **remove/drop** the features `total_rooms`, `total_bedrooms`, `population`, `household`. <br/>\n",
    "To do this automatically, we can create another **transformer** that removes the corresponding numpy array columns after `HousingFeatEngineering` throughout their column indices. <br/>\n",
    "Coincidentally, these column indices are _the same_ used in `HousingFeatEngineering`... but, **always be aware of this.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# our 3 new features are based on some the features: totalrooms, \n",
    "# column index\n",
    "rooms_col_idx, bedrooms_col_idx, population_col_idx, households_col_idx = 3, 4, 5, 6\n",
    "\n",
    "class DropFeatures(BaseEstimator, TransformerMixin):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline for numerical\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-roller",
   "metadata": {},
   "source": [
    "## üèãÔ∏è‚Äç‚ôÄÔ∏è 6. Train ML Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-article",
   "metadata": {},
   "source": [
    "### 6.1. Getting the independent (features) and dependent variables (outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b77547b-7ef2-44e8-b3ab-da93e4e11099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_scenario_1.shape)\n",
    "print(X_train_scenario_1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cb5a1c-0223-439b-9ac0-dda97495aaa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-margin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we already have `y_train`\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-senate",
   "metadata": {},
   "source": [
    "### 6.2. Training the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-sweet",
   "metadata": {},
   "source": [
    "For this initial evaluation, let's consider the **default parameters** of `PolynomialFeatures` but the `include_bias`.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing function\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-broadcasting",
   "metadata": {},
   "source": [
    "#### **‚Üí Scenario 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# default degree = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-voice",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_scenario_1.shape)\n",
    "print(X_train_scenario_1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scores(lin_rmse_scores_scenario_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-warner",
   "metadata": {},
   "source": [
    "Although the errors are relatively _stable_ across the folds (look at the _standard deviation_), the **cross validation score** (\\\\$71,453.19 ¬± \\$1,359.74) is _considerably higher_ than `Linear Regression` (\\\\$58,371.04 ¬± \\$1,757.91)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-article",
   "metadata": {},
   "source": [
    "<table align=\"left\" class=\"dashed-box\">\n",
    "<tr>\n",
    "    <td>üí°</td>\n",
    "    <td>Although we have create a <code>Pipeline</code> only for <b>preprocessing</b>, we could incorporate <b>all steps/modes/transformers</b> (including <code>polynomial transformation</code> and <code>linear regression</code>) into a <b>single <code>Pipeline</code><b/>.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td></td>\n",
    "    <td>We will see that in the next sprints.</td>\n",
    "</tr>\n",
    "</table><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-marsh",
   "metadata": {},
   "source": [
    "#### **‚Üí Scenario 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# default degree = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-hunger",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_scenario_2.shape)\n",
    "print(X_train_scenario_2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scores(lin_rmse_scores_scenario_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-ecuador",
   "metadata": {},
   "source": [
    "This **polynomial regression model** is very unstable (look at the _standard deviation_): it presents lower errors in some folds and extremely high ones in other folds. <br/>\n",
    "It seems that:\n",
    "- this combination of features is not good; and/or\n",
    "- the outliers (regardless their nature) are impacting the results; and/or\n",
    "- the considered degree is not adequate; and/or\n",
    "- this model is not adequate for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-inspection",
   "metadata": {},
   "source": [
    "<table align=\"left\" class=\"dashed-box\">\n",
    "<tr>\n",
    "    <td>üí°</td>\n",
    "    <td>Before ignoring <b>polynomial regression</b> for our problem, we could try to <b><i>fine-tune</i></b> its <i>hyperparameters</i>, especially the <code>degree</code> since it highly impacts the final results, and/or remove outliers.</td>\n",
    "</tr>\n",
    "</table><br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-stephen",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
